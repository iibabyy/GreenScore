# ===== 4. ask.py (modifi√© avec debug complet) =====
from fastapi import APIRouter, Query, HTTPException
from core.ollama_client import get_llm
from rag.rag_chain import build_rag_chain
from rag.vectorstore_manager import VectorStoreManager
import re
import time

router = APIRouter()
vector_store_manager = VectorStoreManager()
vectordb = vector_store_manager.get_vectordb()

def extract_quoted_blocks(text: str):
    """Extrait les blocs format√©s [SOURCE] ```...``` du texte retourn√© par le LLM."""
    pattern = r"\[([^\]]+)\]\s*```(.*?)```"
    return re.findall(pattern, text, flags=re.S)

def verify_blocks_in_sources(blocks, source_docs):
    """V√©rifie que chaque bloc de texte extrait figure bien dans au moins un source_doc."""
    results = []
    for source_label, extrait in blocks:
        extrait_clean = extrait.strip()
        found = any(extrait_clean in doc.page_content for doc in source_docs)
        results.append((source_label, extrait_clean, found))
    return results

@router.post("/debug-retrieval")
def debug_retrieval(question: str = Query(..., description="Question pour tester la r√©cup√©ration")):
    """Route de debug pour v√©rifier la qualit√© de la r√©cup√©ration des documents"""
    print(f"üîç DEBUG RETRIEVAL - Question: {question}")
    
    retriever = vectordb.as_retriever(search_type="similarity", search_kwargs={"k": 5})
    start_time = time.time()
    retrieved_docs = retriever.get_relevant_documents(question)
    retrieval_time = time.time() - start_time
    
    print(f"‚è±Ô∏è Temps de r√©cup√©ration: {retrieval_time:.2f}s")
    print(f"üìö Documents r√©cup√©r√©s: {len(retrieved_docs)}")
    
    for i, doc in enumerate(retrieved_docs):
        print(f"üìÑ Doc {i+1}: {doc.metadata.get('source', 'unknown')} - Page {doc.metadata.get('page', '?')}")
        print(f"   Contenu (100 premiers chars): {doc.page_content[:100]}...")
    
    return {
        "question": question,
        "retrieval_time_seconds": round(retrieval_time, 2),
        "num_documents_found": len(retrieved_docs),
        "retrieved_documents": [
            {
                "source": doc.metadata.get("source", "unknown"),
                "page": doc.metadata.get("page", "unknown"),
                "content_preview": doc.page_content[:400],
                "content_length": len(doc.page_content)
            }
            for doc in retrieved_docs
        ]
    }

MAX_QUESTION_LEN = 500

@router.post("/ask")
def ask(question: str = Query(..., description="Question √† poser au mod√®le")):
    if len(question) > MAX_QUESTION_LEN:
        raise HTTPException(status_code=400, detail=f"Question trop longue (>{MAX_QUESTION_LEN} caract√®res)")
    print(f"\nü§î Question re√ßue: {question}")
    
    # 1. R√©cup√©ration des documents (une seule fois)
    retriever = vectordb.as_retriever(search_type="similarity", search_kwargs={"k": 3})
    start_retrieval = time.time()
    retrieved_docs = retriever.get_relevant_documents(question)
    retrieval_time = time.time() - start_retrieval

    # 2. Construction de la cha√Æne RAG (LLM + prompt) apr√®s avoir les docs
    llm = get_llm()
    qa_chain = build_rag_chain(vectordb, llm=llm, k=3)
    
    print(f"üîç R√©cup√©ration termin√©e en {retrieval_time:.2f}s")
    print(f"üìö {len(retrieved_docs)} documents r√©cup√©r√©s:")
    for i, doc in enumerate(retrieved_docs):
        source = doc.metadata.get("source", "unknown")
        page = doc.metadata.get("page", "?")
        print(f"   üìÑ Doc {i+1}: {source} (page {page}) - {len(doc.page_content)} chars")
    
    # 3. G√©n√©ration de la r√©ponse
    print(f"ü§ñ G√©n√©ration de la r√©ponse avec {llm.model}...")
    start_generation = time.time()
    # Invocation standard
    result = qa_chain.invoke({"query": question})
    generation_time = time.time() - start_generation

    answer = result.get("result", "")
    source_docs = result.get("source_documents", []) or retrieved_docs
    
    print(f"‚è±Ô∏è G√©n√©ration termin√©e en {generation_time:.2f}s")
    print(f"üìù R√©ponse g√©n√©r√©e ({len(answer)} caract√®res):")
    print(f"   {answer[:200]}{'...' if len(answer) > 200 else ''}")
    
    # 4. V√©rification des citations (optionnel)
    blocks = extract_quoted_blocks(answer)
    verification = verify_blocks_in_sources(blocks, source_docs)
    
    warnings = []
    for (src_label, extrait, found) in verification:
        if not found:
            warnings.append({
                "source_label": src_label,
                "excerpt": extrait,
                "status": "NOT_FOUND_IN_DOCS"
            })
    
    if warnings:
        print(f"‚ö†Ô∏è {len(warnings)} citations non v√©rifi√©es d√©tect√©es")
    
    return {
        "question": question,
        "answer": answer,
        "timings": {
            "retrieval_seconds": round(retrieval_time, 2),
            "generation_seconds": round(generation_time, 2),
            "total_seconds": round(retrieval_time + generation_time, 2)
        },
        "source_documents": [
            {
                "source": doc.metadata.get("source", "unknown"), 
                "page": doc.metadata.get("page", None), 
                "text_snippet": doc.page_content[:300]
            }
            for doc in source_docs
        ],
        "debug_info": {
            "num_retrieved_docs": len(retrieved_docs),
            "answer_length": len(answer),
            "warnings_count": len(warnings)
        },
        "warnings": warnings
    }
# Note: Les warnings contiennent les extraits non trouv√©s dans les documents r√©cup√©r√©s